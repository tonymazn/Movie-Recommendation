---
title: "Project 4: Movie Recommendation Report"
author: Zhouning Ma (ZM11)
date: '09/07/2020'
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan

fontfamily: mathpazo
fontfamilyoptions: sc, osf
fontsize: 11pt
linkcolor: blue
---

***



```{r include=FALSE}
start_time <- Sys.time()

library(recommenderlab)
library(ggplot2)
library(data.table)
library(reshape2)
library(knitr)
```


### Project Overview
In this project, we develop content based recommendation system(System I) and collaborative recommendation system(System II) (1).

* **System I:** recommendation based on genres. We know user's favorite genre, we provide two recommendation schemes: 
   + __Method I:__  highly-rate movies - select the 4-point or more review
   + __Method II:__ most trendy movies - the newest movie(here is year 2000)

* **System II:** collaborative recommendation system. we provided three collaborative recommendation algorithms: 
   + __User-based (UBCF):__ we assume that similar users will have similar taste. UBCF uses the logic and recommends items by finding similar users to the user;
   + __Item-based (IBCF):__ The similarities between different items in the dataset are calculated by using one of a number of similarity measures, and then these similarity values are used to predict;
   + __Singular value decomposition (SVD):__ It uses a matrix structure where each row represents a user, and each column represents an item. The elements of this matrix are the ratings that are given to items by users.


```{r include=FALSE}
read <- function(fileName, separators) {
    data <- readLines(con <- file(fileName))
    close(con)
    records <- sapply(data, strsplit, split=separators)
    dataFrame <- data.frame(t(sapply(records,c)))
    rownames(dataFrame) <- 1: nrow(dataFrame)
    return(as.data.frame(dataFrame,stringsAsFactors = FALSE))
}


basedir ="data/test/"
#basedir ="data/"
movies = read(paste0(basedir,"movies.dat"), "::")
ratings = read(paste0(basedir,"ratings.dat"), "::")
users = read(paste0(basedir, "users.dat"), "::")
colnames(movies) = c('MovieID', 'title', 'genres')
colnames(ratings) = c('UserID', 'MovieID', 'Rating', 'Timestamp')
colnames(users) = c('UserID', 'Gender', 'Age', 'Occupation', 'Zip-code')

moviesList <- read(paste0(basedir,"aggr.dat"), "::")
movies_clean <- read(paste0(basedir,"movies_clean.dat"), "::")

colnames(moviesList) = c( 'MovieID', 'AveRating', 'title', 'genres')
colnames(movies_clean) = c("MovieID", "title", "year", 'genres')
genre_list <- c("Action", "Adventure", "Animation", "Children", 
                "Comedy", "Crime","Documentary", "Drama", "Fantasy",
                "Film-Noir", "Horror", "Musical", "Mystery","Romance",
                "Sci-Fi", "Thriller", "War", "Western")
```


### Dataset
The dataset(2) contains about 1 million ratings and the details as following:

* Number of movies: $`r nrow(movies)`$
* Number of ratings: $`r nrow(ratings)`$
* Number of users: $`r nrow(users)`$

The dataset README(3) shows:
Genres are pipe-separated and are selected from the following genres:

* Action
* Adventure
* Animation
* Children's
* Comedy
* Crime
* Documentary
* Drama
* Fantasy
* Film-Noir
- Horror
- Musical
- Mystery
- Romance
- Sci-Fi
- Thriller
- War
- Western
	



```{r include=FALSE}

## Data pre-processing
genres <- as.data.frame(movies[,3], stringsAsFactors=FALSE)
genres2 <- as.data.frame(tstrsplit(genres[,1], '[|]', type.convert=TRUE), stringsAsFactors=FALSE)
colnames(genres2)<- c(1:5)  #c(1:10)

genre_list <- c("Action", "Adventure", "Animation", "Children", 
                "Comedy", "Crime","Documentary", "Drama", "Fantasy",
                "Film-Noir", "Horror", "Musical", "Mystery","Romance",
                "Sci-Fi", "Thriller", "War", "Western")


genre_matrix <- matrix(0,nrow(movies) + 1,18) #empty matrix, 18=no of genres
genre_matrix[1,] <- genre_list #set first row to genre list
colnames(genre_matrix) <- genre_list #set column names to genre list

#iterate through matrix
for (i in 1:nrow(genres2)) {
  for (c in 1:ncol(genres2)) {
    genmat_col = which(genre_matrix[1,] == genres2[i,c])
    genre_matrix[i+1,genmat_col] <- 1
  }
}

#convert into dataframe
genre_matrix2 <- as.data.frame(genre_matrix[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (c in 1:ncol(genre_matrix2)) {
  genre_matrix2[,c] <- as.integer(genre_matrix2[,c])
} 

#Create a matrix to search for a movie by genre:
years <- as.data.frame(movies$title, stringsAsFactors=FALSE)

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

years <- as.data.frame(substr(substrRight(substrRight(years$`movies$title`, 6),5),1,4))
colMin <- function(data) sapply(data, min, na.rm = TRUE)
colMax <- function(data) sapply(data, max, na.rm = TRUE)

min_year = colMin(years)
max_year = colMax(years)

```

The movies' year are between $`r min_year`$ to $`r max_year`$.


```{r include=FALSE}
## Create a user profile
binaryratings <- ratings

# ratings of 4 and 5 are mapped to 1, 
# representing likes, and ratings of 3 
# and below are mapped to -1, representing 
# dislikes:

for (i in 1:nrow(binaryratings)){
  if (binaryratings[i,3] > 3){
    binaryratings[i,3] <- 1
  }
  else{
    binaryratings[i,3] <- -1
  }
}

# convert binaryratings matrix to the correct format:
binaryratings2 <- dcast(binaryratings, MovieID~UserID, value.var = "Rating", na.rm=FALSE)
#head(binaryratings2)


for (i in 1:ncol(binaryratings2)){
  binaryratings2[which(is.na(binaryratings2[,i]) == TRUE),i] <- 0
}
binaryratings2 = binaryratings2[,-1] #remove MovieIDs col. Rows are MovieIDs, cols are userIds
#head(binaryratings2)


#Remove rows that are not rated from movies dataset
MovieIDs <- length(unique(movies$MovieID)) #10329
ratingMovieIDs <- length(unique(ratings$MovieID)) #10325
movies2 <- movies[-which((movies$MovieID %in% ratings$MovieID) == FALSE),]
rownames(movies2) <- NULL

#Remove rows that are not rated from genre_matrix2
genre_matrix3 <- genre_matrix2[-which((movies$MovieID %in% ratings$MovieID) == FALSE),]
rownames(genre_matrix3) <- NULL

#Calculate dot product for User Profiles
result = matrix(0,18,nrow(users)) 
for (c in 1:ncol(binaryratings2)){
  for (i in 1:ncol(genre_matrix3)){
    result[i,c] <- sum((genre_matrix3[,i]) * (as.numeric(binaryratings2[,c]))) #ratings per genre
  }
}

#Convert to Binary scale
for (c in 1:ncol(result)){
  for (i in 1:nrow(result)){
    if (result[i,c] < 0){
      result[i,c] <- 0
    }
    else {
      result[i,c] <- 1
    }
  }
}

## Assume that users like similar items, and retrieve movies 
# that are closest in similarity to a user's profile, which 
# represents a user's preference for an item's feature.
# use Jaccard Distance to measure the similarity between user profiles

# The User-Based Collaborative Filtering Approach

#Create ratings matrix. Rows = userId, Columns = movieId
ratingmat <- dcast(ratings, UserID~MovieID, value.var = "Rating", na.rm=FALSE)
ratingmat <- as.matrix(ratingmat[,-1]) #remove userIds

# Method: UBCF
# Similarity Calculation Method: Cosine Similarity
# Nearest Neighbors: 30

#Convert rating matrix into a recommenderlab sparse matrix
ratingmat <- as(ratingmat, "realRatingMatrix")

# Determine how similar the first four users are with each other
# create similarity matrix
similarity_users <- similarity(ratingmat[1:4, ], 
                               method = "cosine", 
                               which = "users")
as.matrix(similarity_users)

```






### Exploring Similarity Data

```{r echo=TRUE}

image(as.matrix(similarity_users), main = "User similarity")

```


```{r include=FALSE}


# compute similarity between
# the first four movies
similarity_items <- similarity(ratingmat[, 1:4], method =
                                 "cosine", which = "items")
as.matrix(similarity_items)

```


```{r echo=TRUE}

image(as.matrix(similarity_items), main = "Item similarity")

```


### Most Viewed Movies Visualization (4)(5) 

```{r include=FALSE}

# Exploring values of ratings:
vector_ratings <- as.vector(ratingmat@data)
unique(vector_ratings) # what are unique values of ratings

table_ratings <- table(vector_ratings) # what is the count of each rating value
table_ratings


```


```{r echo=TRUE}
# Visualize the rating:
vector_ratings <- vector_ratings[vector_ratings != 0] # rating == 0 are NA values
vector_ratings <- factor(vector_ratings)

qplot(vector_ratings) + 
  ggtitle("Distribution of the ratings")

```


```{r include=FALSE}


# Exploring viewings of movies:
views_per_movie <- colCounts(ratingmat) # count views for each movie
table_views <- data.frame(movie = names(views_per_movie), views = views_per_movie) # create dataframe of views
table_views <- table_views[order(table_views$views, decreasing = TRUE), ] # sort by number of views


#ggplot(table_views[1:6, ], aes(x = movie, y = views)) +
#  geom_bar(stat="identity") + 
#  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
#  scale_x_discrete(labels=subset(movies2, movies2$MovieID == table_views$movie)$title) +
#  ggtitle("Number of views of the top movies")

```


```{r echo=TRUE}


#Visualizing the matrix:
image(ratingmat, main = "Heatmap of the rating matrix") # hard to read-too many dimensions
image(ratingmat[1:10, 1:15], main = "Heatmap of the first rows and columns")
image(ratingmat[rowCounts(ratingmat) > quantile(rowCounts(ratingmat), 0.99),
                 colCounts(ratingmat) > quantile(colCounts(ratingmat), 0.99)], 
      main = "Heatmap of the top users and movies")


#Normalize the data
ratingmat_norm <- normalize(ratingmat)
image(ratingmat_norm[rowCounts(ratingmat_norm) > quantile(rowCounts(ratingmat_norm), 0.99),
                colCounts(ratingmat_norm) > quantile(colCounts(ratingmat_norm), 0.99)], 
      main = "Heatmap of the top users and movies")



```


## Create realRatingMatrix

```{r}
ratings <- as(ratings, 'realRatingMatrix')
```


## Training and Testing Data
We split the data into 80% training and 20% testing. 

```{r}
train_proportion <- 0.8
to_keep <- 15  ## given 15 items
threshold <- 0 ## ratings above 0 as the cutoff point

# split the data into the training and the test set:
e <- evaluationScheme(ratings, method="split", train=train_proportion, k=10, given=to_keep, goodRating=threshold)
e

```


## System I

system I is content based recommendation system, let's say we know the user's favorite genres, we will recommend movies based on genres. 

### Method I: highly-rate movies

  We calculate the average point of each movie and randomly pick N movies which average point is great than 3-point(4-point or 5-point) in the genres. 


```{r}
  # Method 1:
  numberofmovierecommend = 5

  input_genre1 = genre_list[1]
  input_genre2 = genre_list[2]
  input_genre3 = genre_list[3]

  systemresult = subset(moviesList,AveRating>=4 & (grepl(input_genre1, genres, fixed = TRUE) | grepl(input_genre2, genres, fixed = TRUE) | grepl(input_genre3, genres, fixed = TRUE)) )
  if (nrow(systemresult) < numberofmovierecommend){
     systemresult = subset(moviesList, grepl(input_genre1, genres, fixed = TRUE) | grepl(input_genre2, genres, fixed = TRUE) | grepl(input_genre3, genres, fixed = TRUE))
  }

  systemresult = systemresult[sample(nrow(systemresult), ifelse(nrow(systemresult)>=numberofmovierecommend,numberofmovierecommend,nrow(systemresult))),]
  systemresult


```
  
  
  
### Method II:most trendy movies

  The newest movies are year 2000 in the dataset, we will randomly pick N movies from year 2000 in the genres, Unfortunately sometimes there are not enough movies
  in year 2000 for each genres, for example, it is empty in genres "Film-Noir" of year 2000, we have to try the movies of year 1999.
  

```{r}
  # Method 2:
  numberofmovierecommend = 5
  trendyYear = 2000

  input_genre1 = genre_list[1]
  input_genre2 = genre_list[2]
  input_genre3 = genre_list[3]


  systemresult = subset(movies_clean, year >= trendyYear & (grepl(input_genre1, genres, fixed = TRUE) | grepl(input_genre2, genres, fixed = TRUE) | grepl(input_genre3, genres, fixed = TRUE)) )
  if (nrow(systemresult) < numberofmovierecommend){
      systemresult = subset(movies_clean, year >= trendyYear - 1 & (grepl(input_genre1, genres, fixed = TRUE) | grepl(input_genre2, genres, fixed = TRUE) | grepl(input_genre3, genres, fixed = TRUE)) )
  }
  systemresult = systemresult[sample(nrow(systemresult), ifelse(nrow(systemresult)>=numberofmovierecommend,numberofmovierecommend,nrow(systemresult))),]
  systemresult
```


## Train User-based and Item-based Collaborative Filtering models

We will train CF models by difference parameters (7,8):

- normalize: NULL, center or Z-score;

- method: Cosine, Euclidean pearson

also, we will train two SVD models with difference parameter, total **20 models:**, we will calculate prediction accuracy as well, the following are the examples:


### User-Based Collaborative Filtering: Cosine Similarity

   + UBCF_N_C : The raw data is used with no normalization applied;

   + UBCF_C_C: Data are normalized using centering.

   + UBCF_Z_C: Z-score normalization is applied to the data;

```{r}
# train UBCF cosine similarity models
# non-normalized
UBCF_N_C <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = NULL, method="Cosine"))

# centered
UBCF_C_C <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = "center",method="Cosine"))

# Z-score normalization
UBCF_Z_C <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = "Z-score",method="Cosine"))

```

### Evaluate the models:

```{r}
# compute predicted ratings
p1 <- predict(UBCF_N_C, getData(e, "known"), type="ratings")
p2 <- predict(UBCF_C_C, getData(e, "known"), type="ratings")
p3 <- predict(UBCF_Z_C, getData(e, "known"), type="ratings")

# aggregate the performance statistics
error_UCOS <- rbind(
  UBCF_N_C = calcPredictionAccuracy(p1, getData(e, "unknown")),
  UBCF_C_C = calcPredictionAccuracy(p2, getData(e, "unknown")),
  UBCF_Z_C = calcPredictionAccuracy(p3, getData(e, "unknown"))
)
kable(error_UCOS)
```


### User-Based Collaborative Filtering: Euclidean Distance

```{r}
# train UBCF Euclidean Distance models

# non-normalized
UBCF_N_E <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = NULL, method="Euclidean"))

# centered
UBCF_C_E <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = "center",method="Euclidean"))

# Z-score normalization
UBCF_Z_E <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = "Z-score",method="Euclidean"))

```



```{r}
# compute predicted ratings
p1 <- predict(UBCF_N_E, getData(e, "known"), type="ratings")
p2 <- predict(UBCF_C_E, getData(e, "known"), type="ratings")
p3 <- predict(UBCF_Z_E, getData(e, "known"), type="ratings")

# aggregate the performance statistics
error_UEUC <- rbind(
  UBCF_N_E = calcPredictionAccuracy(p1, getData(e, "unknown")),
  UBCF_C_E = calcPredictionAccuracy(p2, getData(e, "unknown")),
  UBCF_Z_E = calcPredictionAccuracy(p3, getData(e, "unknown"))
)
kable(error_UEUC)
```

### User-Based Collaborative Filtering: Pearson Correlation

```{r}
#train UBCF pearson correlation models

# non-normalized
UBCF_N_P <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = NULL, method="pearson"))

# centered
UBCF_C_P <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = "center",method="pearson"))

# Z-score normalization
UBCF_Z_P <- Recommender(getData(e, "train"), "UBCF", param=list(normalize = "Z-score",method="pearson"))

```


```{r}
# compute predicted ratings
p1 <- predict(UBCF_N_P, getData(e, "known"), type="ratings")
p2 <- predict(UBCF_C_P, getData(e, "known"), type="ratings")
p3 <- predict(UBCF_Z_P, getData(e, "known"), type="ratings")

# aggregate the performance statistics
error_UPC <- rbind(
  UBCF_N_P = calcPredictionAccuracy(p1, getData(e, "unknown")),
  UBCF_C_P = calcPredictionAccuracy(p2, getData(e, "unknown")),
  UBCF_Z_P = calcPredictionAccuracy(p3, getData(e, "unknown"))
)
kable(error_UPC)
```


### Item-Based Collaborative Filtering: Cosine Similarity

```{r}
#train IBCF cosine similarity models

# non-normalized
IBCF_N_C <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = NULL, method="Cosine"))

# centered
IBCF_C_C <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = "center",method="Cosine"))

# Z-score normalization
IBCF_Z_C <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = "Z-score",method="Cosine"))

```


```{r}
# compute predicted ratings
p1 <- predict(IBCF_N_C, getData(e, "known"), type="ratings")
p2 <- predict(IBCF_C_C, getData(e, "known"), type="ratings")
p3 <- predict(IBCF_Z_C, getData(e, "known"), type="ratings")


# aggregate the performance statistics
error_ICOS <- rbind(
  IBCF_N_C = calcPredictionAccuracy(p1, getData(e, "unknown")),
  IBCF_C_C = calcPredictionAccuracy(p2, getData(e, "unknown")),
  IBCF_Z_C = calcPredictionAccuracy(p3, getData(e, "unknown"))
)

kable(error_ICOS)

```

### Item-Based Collaborative Filtering: Euclidean Distance

```{r}
#train IBCF Euclidean Distance models

# non-normalized
IBCF_N_E <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = NULL, method="Euclidean"))

# centered
IBCF_C_E <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = "center",method="Euclidean"))

# Z-score normalization
IBCF_Z_E <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = "Z-score",method="Euclidean"))
```

```{r}
# compute predicted ratings
p1 <- predict(IBCF_N_E, getData(e, "known"), type="ratings")
p2 <- predict(IBCF_C_E, getData(e, "known"), type="ratings")
p3 <- predict(IBCF_Z_E, getData(e, "known"), type="ratings")


# aggregate the performance statistics
error_IEUC <- rbind(
  IBCF_N_E = calcPredictionAccuracy(p1, getData(e, "unknown")),
  IBCF_C_E = calcPredictionAccuracy(p2, getData(e, "unknown")),
  IBCF_Z_E = calcPredictionAccuracy(p3, getData(e, "unknown"))
)
kable(error_IEUC)
```


### Item-Based Collaborative Filtering: Pearson Correlation

```{r}
#train IBCF pearson correlation models

# non-normalized
IBCF_N_P <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = NULL, method="pearson"))

# centered
IBCF_C_P <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = "center",method="pearson"))

# Z-score normalization
IBCF_Z_P <- Recommender(getData(e, "train"), "IBCF", param=list(normalize = "Z-score",method="pearson"))

```


```{r}
# compute predicted ratings
p1 <- predict(IBCF_N_P, getData(e, "known"), type="ratings")
p2 <- predict(IBCF_C_P, getData(e, "known"), type="ratings")
p3 <- predict(IBCF_Z_P, getData(e, "known"), type="ratings")

# aggregate the performance statistics
error_IPC <- rbind(
  IBCF_N_P = calcPredictionAccuracy(p1, getData(e, "unknown")),
  IBCF_C_P = calcPredictionAccuracy(p2, getData(e, "unknown")),
  IBCF_Z_P = calcPredictionAccuracy(p3, getData(e, "unknown"))
)
kable(error_IPC)

```


## SVD models

- One is Latent-Factor Collaborative Filtering Recommender
- SVD with default parameter, we call it no-para

```{r}
# Latent-Factor Collaborative Filtering Recommender SVD
latent_factor_cofi_rec_SVD <- Recommender(data=getData(e, "train"), method="SVD",parameter=list(categories=30,normalize='center',method='Pearson'))

# SVD with default parameters
no_para_svd <- Recommender(data=getData(e, "train"), method="SVD")
```


```{r}
# compute predicted ratings
p1 <- predict(latent_factor_cofi_rec_SVD, getData(e, "known"), type="ratings")
p2 <- predict(no_para_svd, getData(e, "known"), type="ratings")

# aggregate the performance statistics
error_SVD <- rbind(
  latent_factor_cofi_rec_SVD = calcPredictionAccuracy(p1, getData(e, "unknown")),
  no_para_SVD = calcPredictionAccuracy(p2, getData(e, "unknown"))
)
kable(error_SVD)

```





```{r}
# memory cleanup
rm(IBCF_N_P, IBCF_C_P, IBCF_Z_P)
```

```{r}
c_res <- data.frame(rbind(error_UCOS, error_UEUC, error_UPC, error_ICOS, error_IEUC, error_IPC, error_SVD))
c_res <- c_res[order(c_res$RMSE ),]
kable(c_res)
```


```{r}
barplot(c_res$RMSE, col = "yellow", main = "Model RMSEs", las = 2, ylab = "RMSE", horiz = FALSE, names.arg = rownames(c_res), cex.names=.8)
```




## Evaluation result
It looks like the SVDs' performance(prediction accuracy) are better than User-based and Item-based Collaborative Filtering. 


## Save pre-trained models
It takes time to train a model with large data, to save time for the App, we will store the model object to  .rds format, when the system starts, 
it will load the .rds to the model object. it will be very fast. We save all the models we tested, it is around 20 models.

## Movie Recommendation App

  * it is a shiny app with System I and System II algorithms
  * System I
    + the app needs to take the input from users on their favorite genres, and display the result
    + system will provide two methods for System I (you are able to select any of them by the setting)
  
 * System II 
   + the app need the users to rate many movies as possible;
   + system will discover movies for the users by User-based or Item-based Collaborative Filtering models or SVD models

 * Setting
   + select the algorithm for System I
   + select the algorithm for System II


## Deploy the App
it is a huge challenge to deploy to Shiny server, it doesn't support the dataset like us(1M rows), but we found a way finally to make it successfully, 
we are able to running the App on the full dataset, but it is not for production, it is ok for the proof of concept. We found it is stable when we work
RStudio on windows environment, why don't we use this one to demonstrate? Once we are able to change the web server port to 80, then we are able to host.
We run the following code on RStudio console:

**runApp('app', host = "0.0.0.0", port = 80)**


anther thing we need to do is the server will shutdown in 1 hour, we need to ping(wget can do this job) it every 10 minutes.






```{r}
Sys.time() - start_time
```

## Reference 
1. Piazza:  https://piazza.com/class/kdf6l5f8bb78j?cid=868
2. Moviewlens: https://grouplens.org/datasets/movielens/
3. Dataset README: https://github.com/tonymazn/stat542/tree/main/data/README
4. Machine Learning Project â€“ Data Science Movie Recommendation System Project in R 
   https://data-flair.training/blogs/data-science-r-movie-recommendation/
5. Movie Recommendation System: https://jeknov.shinyapps.io/movieRec/
6. Item-Based Collaborative Filtering Recommendation: 
   https://www.kaggle.com/hendraherviawan/itembased-collaborative-filter-recommendation-r
7. User-Based and Item-Based Collaborative Filtering https://rpubs.com/jt_rpubs/285729
8. Movie Recommendation System  https://jeknov.shinyapps.io/movieRec/
